{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torchvision\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\nimport matplotlib.pyplot as plt\nimport torch.utils.data.sampler\nimport torchvision.transforms.functional as TF\nfrom torch.utils.data import DataLoader as DL\nfrom torch.utils.data import *\nfrom PIL import Image, ImageFilter\nimport os\nimport cv2\nimport numpy\nimport random\nimport fnmatch\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.load('/input/lsunchurch/church_outdoor_train_lmdb_color_64.npy')\nprint(X_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs=16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train = X_train[0:(126227-(126227%bs))]\n#X_train = X_train[0:16000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_train[16000:17600]\nX_train = X_train[0:16000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = DataLoader(X_train, batch_size=bs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader = DataLoader(X_test, batch_size=bs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(d)\nlen(test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def en_double_conv(in_channels, out_channels):\n    return nn.Sequential(\n        nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n        nn.LeakyReLU(0.2, inplace=True),\n        nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n        nn.BatchNorm2d(out_channels),\n        nn.LeakyReLU(0.2, inplace=True)\n    )\n\ndef dec_double_conv(in_channels, out_channels):\n  return nn.Sequential(\n      nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n      nn.ReLU(inplace=True),\n      nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n      nn.BatchNorm2d(out_channels),\n      nn.ReLU(inplace=True)\n  )\n\nn=6\n\nclass G(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        self.dconv_1 = en_double_conv(3, n)\n        self.dconv_2 = en_double_conv(n, n*2)\n        self.dconv_3 = en_double_conv(n*2, n*4)\n        self.dconv_4 = en_double_conv(n*4, n*8)\n        self.dconv_5 = en_double_conv(n*8, n*8*2)\n        self.dconv_6 = en_double_conv(n*8*2, n*8*3)\n\n        self.dropout = nn.Dropout(0.5)\n        self.maxpool = nn.MaxPool2d(2)\n\n        self.TConv6 = nn.ConvTranspose2d(n*8*3, n*8*3, 4, 2, 1)\n        self.TConv5 = nn.ConvTranspose2d(n*8*5, n*8*5, 4, 2, 1)\n        self.TConv4 = nn.ConvTranspose2d(n*8*6, n*8*6, 4, 2, 1)\n        self.TConv3 = nn.ConvTranspose2d(n*52, n*52, 4, 2, 1)\n        self.TConv2 = nn.ConvTranspose2d(n*54, n*54, 4, 2, 1)\n        self.TConv1 = nn.ConvTranspose2d(n*55, 3, 4, 2, 1)\n        \n    def forward(self, x):\n        conv1 = self.dconv_1(x)\n        conv1 = self.maxpool(conv1)\n\n        conv2 = self.dconv_2(conv1)\n        conv2 = self.maxpool(conv2)\n\n        conv3 = self.dconv_3(conv2)\n        conv3 = self.maxpool(conv3)\n\n        conv4 = self.dconv_4(conv3)\n        conv4 = self.maxpool(conv4)\n\n        conv5 = self.dconv_5(conv4)\n        conv5 = self.maxpool(conv5)\n\n        conv6 = self.dconv_6(conv5)\n        conv6 = self.maxpool(conv6)\n\n        x = self.TConv6(conv6)\n\n        x = torch.cat([x, conv5], dim=1)\n        x = self.TConv5(x)\n        #x = self.dropout(x)\n\n        x = torch.cat([x, conv4], dim=1)\n        x = self.TConv4(x)\n        #x = self.dropout(x)\n\n        x = torch.cat([x, conv3], dim=1)\n        x = self.TConv3(x)\n        #x = self.dropout(x)\n\n        x = torch.cat([x, conv2], dim=1)\n        x = self.TConv2(x)\n        #x = self.dropout(x)\n        \n        x = torch.cat([x, conv1], dim=1)\n        x = self.TConv1(x)\n        x = nn.Tanh()(x)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class D(nn.Module):\n  def __init__(self):\n    super(D, self).__init__()\n    self.main = nn.Sequential(        \n        nn.Conv2d(3, 64, 2, 2, 0),\n        nn.LeakyReLU(0.2),\n        \n        nn.Conv2d(64, 128, 2, 2, 0),\n        nn.BatchNorm2d(128),\n        nn.LeakyReLU(0.2),\n        \n        nn.Conv2d(128, 256, 2, 2, 0),\n        nn.BatchNorm2d(256),\n        nn.LeakyReLU(0.2),\n        \n        nn.Conv2d(256, 512, 2, 2, 0),\n        nn.BatchNorm2d(512),\n        nn.LeakyReLU(0.2),\n        \n        nn.Conv2d(512, 1024, 2, 2, 0),\n        nn.BatchNorm2d(1024),\n        nn.LeakyReLU(0.2),\n        \n        nn.Conv2d(1024, 1, 2, 2, 0),\n        nn.Sigmoid()\n    )\n    \n  def forward(self, im):\n    return self.main(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Generator = G().to(device)\nDiscriminator = D().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def weights_init(m):\n    if isinstance(m, nn.Conv2d):\n        m.weight.data.normal_(0, 0.02)\n        m.bias.data.normal_(0, 0.001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights_init(Generator)\nweights_init(Discriminator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Number of parameters in Generator: \", sum([p.numel() for p in Generator.parameters()]))\nprint(\"Number of parameters in Discriminator: \", sum([p.numel() for p in Discriminator.parameters()]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = nn.BCELoss()\nadv_criterion = nn.BCELoss()\nl1_criterion = nn.L1Loss()\nG_optim = torch.optim.Adam(Generator.parameters(), lr=1e-4)\nD_optim = torch.optim.Adam(Discriminator.parameters(), lr=1e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Discriminator.train()\nGenerator.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_pic(epoch_no, im):\n  Generator.eval()\n  im = im.unsqueeze(0).to(device)\n\n  #transforms.ToPILImage()(im[0]).save(\"input.jpg\") #save input image.\n\n  output = Generator(im)\n  \n  output = output[0].detach().cpu()\n  output = output.clamp(0.0, 1.0)\n\n  PIL_img = transforms.ToPILImage()(output)\n  PIL_img = PIL_img.save(str(epoch_no) + \".jpg\")\n  Generator.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"D_losses_train = []\nG_losses_train = []\n\nD_losses_test = []\nG_losses_test = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def shuffle_data(fake_im, real_im):\n  batch_size=fake_im.shape[0]\n  data=torch.cat((fake_im, real_im),dim=0)\n  labels=torch.cat((torch.zeros(batch_size), torch.ones(batch_size)))\n  \n  return data, labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment_image(real_im): #crop nxn region of images, real_crop, return mask\n  augmented_image = real_im\n  \n  #transforms.ToPILImage()(real_im[0]).save(\"pre-augmentation.jpg\")\n\n  a_size=16\n  mask = torch.ones(real_im.shape)\n  real_crop = torch.zeros(real_im.shape[0], 3, a_size, a_size)\n\n  for i in range(real_im.shape[0]):\n    lim = real_im.shape[2]-a_size\n\n    #r_x = random.randrange(0, lim-1)\n    #r_y = random.randrange(0, lim-1)\n\n    r_x = 24\n    r_y = 24\n\n    for x in range(a_size):\n      for y in range(a_size):\n        for c in range(3):\n          augmented_image[i][c][r_x+x][r_y+y]=0.5\n          real_crop[i][c][x][y]=real_im[i][c][r_x+x][r_y+y]\n          mask[i][c][r_x+x][r_y+y]=1000\n\n  #transforms.ToPILImage()(augmented_image[0]).save(\"augmented.jpg\")\n\n  return augmented_image, real_crop, mask","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 30\n\nfor epoch in range(n_epochs):\n  D_train_loss = 0.0\n  G_train_loss = 0.0\n\n  D_test_loss = 0.0\n  G_test_loss = 0.0\n\n  for i, real_im in enumerate(d):\n    real_im = real_im.permute(0, 3, 1, 2)\n    real_im = real_im.type(torch.FloatTensor)/255\n\n    augmented_im, real_crop, mask = augment_image(real_im)\n    augmented_im = augmented_im.to(device)\n    mask = mask.to(device)\n    #real_crop = real_crop.to(device)\n    real_im = real_im.type(torch.FloatTensor)\n    \n    if i%1599==0:\n      save_pic(epoch, real_im[0])\n\n    ##########Train the discriminator##########\n    D_optim.zero_grad()\n    real_im=real_im.to(device)\n    fake_img = Generator(augmented_im)\n\n    #transforms.ToPILImage()(real_im[0]).save(\"real_im.jpg\")\n\n    data, labels = shuffle_data(fake_img, real_im)\n    guess = Discriminator(data)\n    \n    D_loss = criterion(guess, labels.to(device))\n    D_train_loss += D_loss.item()\n    D_loss.backward()\n    D_optim.step()\n    ###########################################\n    \n    ############Train the generator############ (curriculum training, Foreground-aware II)\n\n    ##########L1 loss update############\n    G_optim.zero_grad()\n    fake_img = Generator(augmented_im)\n\n    G_loss_l1 = l1_criterion(fake_img, real_im)\n    G_train_loss += G_loss_l1.item() #for plotting loss\n    G_loss_l1.backward(retain_graph=True)\n    G_optim.step()\n    ####################################\n    \n    ##########Adversarial loss update###\n    G_optim.zero_grad()\n    #fake_img = Generator(augmented_im) #no need for this\n    guess = Discriminator(fake_img).view(-1)\n    G_loss_adv = adv_criterion(guess, torch.ones(bs).to(device))*1e-2\n    G_train_loss += G_loss_adv.item() #for plotting loss\n    G_loss_adv.backward()\n    G_optim.step()\n    ####################################\n    \n    ###########################################\n  \n  for i, real_im in enumerate(test_loader):\n    Generator.eval()\n    Discriminator.eval()\n    \n    real_im = real_im.permute(0, 3, 1, 2)\n    real_im = real_im.type(torch.FloatTensor)/255\n    \n    augmented_img, _, _ = augment_image(real_im)\n    augmented_img = augmented_img.to(device)\n    real_im = real_im.to(device)\n    \n    fake_img = Generator(augmented_img)\n    guess = Discriminator(augmented_img)\n    adv_loss = adv_criterion(guess, torch.ones(bs).to(device))\n    l1_loss = l1_criterion(augmented_img, real_im)\n    G_loss = adv_loss*1e-2 + l1_loss\n    G_test_loss += G_loss.item()\n    \n    Generator.train()\n    Discriminator.train()\n    \n  G_train_loss = G_train_loss/16000\n  G_test_loss = G_test_loss/1600\n  print(\"Epoch \" + str(epoch) + \", Train: \" + str(G_train_loss))# + \" , Test: \" + str(G_test_loss))\n  G_losses_train.append(G_train_loss)\n  #G_losses_test.append(G_test_loss)\n  #save_pic(epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(Generator.state_dict(), \"lsunChurchGenerator\")\ntorch.save(Discriminator.state_dict(), \"lsunChurchDiscriminator\")\ntorch.save(G_optim.state_dict(), \"lsunChurchG_optim\")\ntorch.save(D_optim.state_dict(), \"lsunChurchD_optim\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}